{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from common.connectors.elastic import ESClient\n",
    "from common.handlers import csv_read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price_index(es: ESClient, municipality_id_filter: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This functions queries ES for all the historical price indexes for every\n",
    "    municipality in the given municipality_id_filter list.\n",
    "    :param es: AvixES elastic client\n",
    "    :param municipality_id_filter: List of municipality codes\n",
    "    :return: pd.DataFrame\n",
    "    \"\"\"\n",
    "    query_condition = \" OR \".join([str(n) for n in municipality_id_filter])\n",
    "    q = {\"query\": {\"bool\": {\"must\": [{\"match\": {\"gemeentecode\": query_condition}}]}}}\n",
    "    result = es.findall(query=q, index=\"dev_realestate.avix_nl_corop_index\")\n",
    "    # result is of the type list and will be empty if Elastic Search could not find the estate\n",
    "    if result:\n",
    "        # Cleaning up results\n",
    "        result_df = pd.DataFrame(hit[\"_source\"] for hit in result)\n",
    "        results_df = (result_df\n",
    "                      .rename(columns={\"avix_corop_index\": \"index\", \"gemeentecode\": \"mun_code\"})\n",
    "                      .filter([\"index\", \"mun_code\", \"year\", \"quarter\"])\n",
    "                      .astype({\"index\": float, \"mun_code\": int}))\n",
    "        assert 3 in results_df['mun_code'].unique().tolist()\n",
    "        return results_df\n",
    "\n",
    "\n",
    "def add_indexed_transactions(es: ESClient, df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Used for querying historical price indices per municipality, and using these to index the\n",
    "    historical sale prices to the most recently available index (usually last yearly quarter).\n",
    "    :param es: AvixES elastic client\n",
    "    :param df: This needs to be the nearby_estates dataframe\n",
    "    :return: The original input dataframe, with additional columns \"indexed_price\" and \"indexed_date\"\n",
    "    \"\"\"\n",
    "    original_columns = df.columns.tolist()\n",
    "\n",
    "    # Getting the price indices from ES\n",
    "    df[\"mun_code\"] = df[\"mun_code\"].astype(int)\n",
    "    nearby_mun_codes = df['mun_code'].unique().tolist()\n",
    "    price_indices = get_price_index(es, nearby_mun_codes)\n",
    "    for mun in nearby_mun_codes:\n",
    "        _sorted = price_indices[price_indices[\"mun_code\"] == mun].sort_values([\"year\", \"quarter\"])\n",
    "        first = _sorted.iloc[0].tolist()\n",
    "        last = _sorted.iloc[-1].tolist()\n",
    "    \n",
    "    # Preparing dataframes for joining\n",
    "    price_indices[\"YQ\"] = price_indices['year'] + '-Q' + price_indices['quarter']\n",
    "    df[\"YQ\"] = df[\"date\"].dt.year.apply(str) + '-Q' + df[\"date\"].dt.quarter.apply(str)\n",
    "    most_recent_index = price_indices[price_indices[\"YQ\"] == price_indices.groupby(\"mun_code\")[\"YQ\"].transform(max)]\n",
    "    most_recent_index = most_recent_index.rename(columns={\"index\": \"current_index\", \"YQ\": \"indexed_date\"})\n",
    "    most_recent_yq = most_recent_index[\"indexed_date\"].iloc[0]\n",
    "    \n",
    "    # If we have sales more recent than the most current indices, we change their YQ to the most recent index so that\n",
    "    # we index the prices to that quarter. Here we assume that all municipalities have the same most-recent-yq.\n",
    "    df.loc[df[\"YQ\"] > most_recent_yq, \"YQ\"] = most_recent_yq\n",
    "    \n",
    "    # Joining and doing the indexing calculations\n",
    "    df_indexed = df.merge(price_indices, on=[\"YQ\", \"mun_code\"])\n",
    "    df_indexed = df_indexed.merge(most_recent_index, on=\"mun_code\")\n",
    "    for key in (\"current_index\", \"amount\", \"index\"):\n",
    "        if df_indexed[key].dtype == \"object\":\n",
    "            df_indexed[key] = df_indexed[key].astype(float)\n",
    "    df_indexed = df_indexed.assign(indexed_price=lambda x: x[\"current_index\"] * x[\"amount\"] / x[\"index\"])\n",
    "    df_indexed = df_indexed.filter(original_columns + [\"indexed_price\", \"indexed_date\"])\n",
    "    \n",
    "    if len(df) - len(df_indexed) > 0:\n",
    "        print(f\"We dropped {len(df) - len(df_indexed)} when joining on price indices!\")\n",
    "        dropped = df.merge(price_indices, on=[\"YQ\", \"mun_code\"], how=\"outer\").query(\"quarter != quarter\")[\"YQ\"]\n",
    "        print(f\"{len(dropped)} of these were dropped due to missing YQ values: {dropped.unique().tolist()}\")\n",
    "\n",
    "    return df_indexed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('C:/Users/PSaalbrink/Google Drive/DDMA Hackathon/buurt_data (1).csv'),\n",
       " WindowsPath('C:/Users/PSaalbrink/Google Drive/DDMA Hackathon/GROENE_DAKEN.csv'),\n",
       " WindowsPath('C:/Users/PSaalbrink/Google Drive/DDMA Hackathon/hackathon.csv')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path.home() / \"Google Drive/DDMA Hackathon\"\n",
    "list(path.glob(\"*.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_data = [{**d,\n",
    "             \"mun_code\": d[\"Gemeente2019\"],\n",
    "             \"buurt_code\": d[\"Buurt2019\"].rjust(8, \"0\"),\n",
    "             \"date\": datetime.strptime(d[\"date\"], \"%d/%m/%Y\")\n",
    "    } for d in csv_read(path / \"hackathon.csv\")\n",
    "           if \"2019\" in d[\"date\"]]\n",
    "red_data = pd.DataFrame(red_data, dtype=str)\n",
    "red_data[\"date\"] = pd.to_datetime(red_data[\"date\"])\n",
    "\n",
    "cbs_data = [d for d in csv_read(path / \"buurt_data.csv\")]\n",
    "cbs_data = pd.DataFrame(cbs_data, dtype=str).drop(columns=\"\")\n",
    "\n",
    "data = pd.merge(cbs_data, red_data, left_on=\"gwb_code_10\", right_on=\"Buurt2019\", how=\"right\")\n",
    "del red_data, cbs_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.columns.tolist()\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "avix = ESClient(\"dev_realestate.avix_nl_corop_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = add_indexed_transactions(avix, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(path / \"complete_hackathon_dataset.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
