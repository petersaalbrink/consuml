{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from warnings import simplefilter\n",
    "simplefilter(\"ignore\")\n",
    "\n",
    "import kmodes\n",
    "import missingno\n",
    "from missingpy import KNNImputer\n",
    "import pandas as pd\n",
    "from pandas_profiling import ProfileReport\n",
    "from sklearn.preprocessing import RobustScaler  # , Normalizer, StandardScaler\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "\n",
    "from common.connectors.elastic import ESClient\n",
    "from common.handlers import csv_read\n",
    "avix = ESClient(\"dev_realestate.avix_nl_corop_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price_index(es: ESClient, municipality_id_filter: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This functions queries ES for all the historical price indexes for every\n",
    "    municipality in the given municipality_id_filter list.\n",
    "    :param es: AvixES elastic client\n",
    "    :param municipality_id_filter: List of municipality codes\n",
    "    :return: pd.DataFrame\n",
    "    \"\"\"\n",
    "    query_condition = \" OR \".join([str(n) for n in municipality_id_filter])\n",
    "    q = {\"query\": {\"bool\": {\"must\": [{\"match\": {\"gemeentecode\": query_condition}}]}}}\n",
    "    result = es.findall(query=q, index=\"dev_realestate.avix_nl_corop_index\")\n",
    "    # result is of the type list and will be empty if Elastic Search could not find the estate\n",
    "    if result:\n",
    "        # Cleaning up results\n",
    "        result_df = pd.DataFrame(hit[\"_source\"] for hit in result)\n",
    "        results_df = (result_df\n",
    "                      .rename(columns={\"avix_corop_index\": \"index\", \"gemeentecode\": \"mun_code\"})\n",
    "                      .filter([\"index\", \"mun_code\", \"year\", \"quarter\"])\n",
    "                      .astype({\"index\": float, \"mun_code\": int}))\n",
    "        assert 3 in results_df[\"mun_code\"].unique().tolist()\n",
    "        return results_df\n",
    "\n",
    "\n",
    "def add_indexed_transactions(es: ESClient, df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Used for querying historical price indices per municipality, and using these to index the\n",
    "    historical sale prices to the most recently available index (usually last yearly quarter).\n",
    "    :param es: AvixES elastic client\n",
    "    :param df: This needs to be the nearby_estates dataframe\n",
    "    :return: The original input dataframe, with additional columns \"indexed_price\" and \"indexed_date\"\n",
    "    \"\"\"\n",
    "    original_columns = df.columns.tolist()\n",
    "\n",
    "    # Getting the price indices from ES\n",
    "    df[\"mun_code\"] = df[\"mun_code\"].astype(int)\n",
    "    nearby_mun_codes = df[\"mun_code\"].unique().tolist()\n",
    "    price_indices = get_price_index(es, nearby_mun_codes)\n",
    "    for mun in nearby_mun_codes:\n",
    "        _sorted = price_indices[price_indices[\"mun_code\"] == mun].sort_values([\"year\", \"quarter\"])\n",
    "        first = _sorted.iloc[0].tolist()\n",
    "        last = _sorted.iloc[-1].tolist()\n",
    "    \n",
    "    # Preparing dataframes for joining\n",
    "    price_indices[\"YQ\"] = price_indices[\"year\"] + \"-Q\" + price_indices[\"quarter\"]\n",
    "    df[\"YQ\"] = df[\"date\"].dt.year.apply(str) + \"-Q\" + df[\"date\"].dt.quarter.apply(str)\n",
    "    most_recent_index = price_indices[price_indices[\"YQ\"] == price_indices.groupby(\"mun_code\")[\"YQ\"].transform(max)]\n",
    "    most_recent_index = most_recent_index.rename(columns={\"index\": \"current_index\", \"YQ\": \"indexed_date\"})\n",
    "    most_recent_yq = most_recent_index[\"indexed_date\"].iloc[0]\n",
    "    \n",
    "    # If we have sales more recent than the most current indices, we change their YQ to the most recent index so that\n",
    "    # we index the prices to that quarter. Here we assume that all municipalities have the same most-recent-yq.\n",
    "    df.loc[df[\"YQ\"] > most_recent_yq, \"YQ\"] = most_recent_yq\n",
    "    \n",
    "    # Joining and doing the indexing calculations\n",
    "    df_indexed = df.merge(price_indices, on=[\"YQ\", \"mun_code\"])\n",
    "    df_indexed = df_indexed.merge(most_recent_index, on=\"mun_code\")\n",
    "    for key in (\"current_index\", \"amount\", \"index\"):\n",
    "        if df_indexed[key].dtype == \"object\":\n",
    "            df_indexed[key] = df_indexed[key].astype(float)\n",
    "    df_indexed = df_indexed.assign(indexed_price=lambda x: x[\"current_index\"] * x[\"amount\"] / x[\"index\"])\n",
    "    df_indexed = df_indexed.filter(original_columns + [\"indexed_price\", \"indexed_date\"])\n",
    "    \n",
    "    if len(df) - len(df_indexed) > 0:\n",
    "        print(f\"We dropped {len(df) - len(df_indexed)} when joining on price indices!\")\n",
    "        dropped = df.merge(price_indices, on=[\"YQ\", \"mun_code\"], how=\"outer\").query(\"quarter != quarter\")[\"YQ\"]\n",
    "        print(f\"{len(dropped)} of these were dropped due to missing YQ values: {dropped.unique().tolist()}\")\n",
    "\n",
    "    return df_indexed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('C:/Users/PSaalbrink/Google Drive/DDMA Hackathon/buurt_data.csv'),\n",
       " WindowsPath('C:/Users/PSaalbrink/Google Drive/DDMA Hackathon/complete_hackathon_dataset.csv'),\n",
       " WindowsPath('C:/Users/PSaalbrink/Google Drive/DDMA Hackathon/GROENE_DAKEN.csv'),\n",
       " WindowsPath('C:/Users/PSaalbrink/Google Drive/DDMA Hackathon/hackathon.csv')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path.home() / \"Google Drive/DDMA Hackathon\"\n",
    "list(path.glob(\"*.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_data = [{**d,\n",
    "             \"mun_code\": d[\"Gemeente2019\"],\n",
    "             \"buurt_code\": d[\"Buurt2019\"].rjust(8, \"0\"),\n",
    "             \"date\": datetime.strptime(d[\"date\"], \"%d/%m/%Y\")\n",
    "    } for d in csv_read(path / \"hackathon.csv\")\n",
    "           if \"2019\" in d[\"date\"]]\n",
    "red_data = pd.DataFrame(red_data).drop(columns=[\"lon\", \"lat\"])\n",
    "red_data[\"date\"] = pd.to_datetime(red_data[\"date\"])\n",
    "\n",
    "cbs_data = [d for d in csv_read(path / \"buurt_data.csv\")]\n",
    "cbs_data = pd.DataFrame(cbs_data).drop(columns=[\"\", \"postcode\"])\n",
    "\n",
    "data = pd.merge(cbs_data, red_data, left_on=\"gwb_code_10\", right_on=\"Buurt2019\", how=\"inner\")\n",
    "data.columns = [col.lower() for col in data.columns]\n",
    "del red_data, cbs_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_keys = [\n",
    "    \"mannen\",\n",
    "    \"vrouwen\",\n",
    "    \"0_tot_15\",\n",
    "    \"15_tot_25\",\n",
    "    \"25_tot_45\",\n",
    "    \"45_tot_65\",\n",
    "    \"65_+\",\n",
    "    \"ongehuwd\",\n",
    "    \"gehuwd\",\n",
    "    \"gescheiden\",\n",
    "    \"migratieachtergrond\",\n",
    "    \"geboorte_relatief\",\n",
    "    \"sterfte_relatief\",\n",
    "    \"eenpersoonshuishoudens\",\n",
    "    \"huishoudens_zonder_kinderen\",\n",
    "    \"huishoudens_met_kinderen\",\n",
    "    \"gemiddelde_huishoudensgrootte\",\n",
    "    \"bevolkingsdichtheid\",\n",
    "    \"percentage_eengezinswoning\",\n",
    "    \"percentage_meergezinswoning\",\n",
    "    \"percentage_bewoond\",\n",
    "    \"percentage_onbewoond\",\n",
    "    \"koopwoningen\",\n",
    "    \"huurwoningen\",\n",
    "    \"elektriciteitsverbruik\",\n",
    "    \"aardgasverbruik\",\n",
    "    \"bedrijfsvestigingen\",\n",
    "    \"landbouw_bosbouw_visserij\",\n",
    "    \"nijverheid_energie\",\n",
    "    \"handel_horeca\",\n",
    "    \"vervoer_informatie_communicatie\",\n",
    "    \"financiële_diensten_onroerendgoed\",\n",
    "    \"zakelijke_dienstverlening\",\n",
    "    \"cultuur_recreatie_overige\",\n",
    "    \"personenautos_brandstof\",\n",
    "    \"personenautos_overige_brandstof\",\n",
    "    \"personenautos_huishouden\",\n",
    "    \"personenautos_oppervlakte\",\n",
    "    \"motorfietsen\",\n",
    "    \"oppervlakte\",\n",
    "    \"oppervlakte_land\",\n",
    "    \"oppervlakte_water\",\n",
    "    \"omgevingsadressendichtheid\",\n",
    "    \"score_totaal_2018\",\n",
    "    \"score_woningen_2018\",\n",
    "    \"score_bewoners_2018\",\n",
    "    \"score_voorzieningen_2018\",\n",
    "    \"score_veiligheid_2018\",\n",
    "    \"score_omgeving_2018\",\n",
    "    \"score_totaal_2012\",\n",
    "    \"score_woningen_2012\",\n",
    "    \"score_bewoners_2012\",\n",
    "    \"score_voorzieningen_2012\",\n",
    "    \"score_veiligheid_2012\",\n",
    "    \"score_omgeving_2012\",\n",
    "    \"score_totaal_ontw\",\n",
    "    \"score_woningen_ontw\",\n",
    "    \"score_bewoners_ontw\",\n",
    "    \"score_voorzieningen_ontw\",\n",
    "    \"score_veiligheid_ontw\",\n",
    "    \"score_omgeving_ontw\",\n",
    "]\n",
    "int_keys = [\n",
    "    \"aantal_inwoners\",\n",
    "    \"huishoudens\",\n",
    "    \"woningvoorraad\",\n",
    "    \"personenautos\",\n",
    "    \"amount\",\n",
    "    \"build_year\",\n",
    "    \"use_surface\",\n",
    "    \"parcel_surface\",\n",
    "    \"number_of_objects\",\n",
    "]\n",
    "scale_keys = [\n",
    "    *int_keys,\n",
    "    \"gemiddelde_huishoudensgrootte\",\n",
    "    \"bevolkingsdichtheid\",\n",
    "    \"elektriciteitsverbruik\",\n",
    "    \"aardgasverbruik\",\n",
    "    \"bedrijfsvestigingen\",\n",
    "    \"landbouw_bosbouw_visserij\",\n",
    "    \"nijverheid_energie\",\n",
    "    \"handel_horeca\",\n",
    "    \"vervoer_informatie_communicatie\",\n",
    "    \"financiële_diensten_onroerendgoed\",\n",
    "    \"zakelijke_dienstverlening\",\n",
    "    \"cultuur_recreatie_overige\",\n",
    "    \"personenautos_oppervlakte\",\n",
    "    \"motorfietsen\",\n",
    "    \"oppervlakte\",\n",
    "    \"oppervlakte_land\",\n",
    "    \"oppervlakte_water\",\n",
    "    \"omgevingsadressendichtheid\",\n",
    "    \"indexed_price\"\n",
    "]\n",
    "perc_keys = [\n",
    "    \"percentage_eengezinswoning\",\n",
    "    \"percentage_meergezinswoning\",\n",
    "    \"percentage_bewoond\",\n",
    "    \"percentage_onbewoond\",\n",
    "    \"koopwoningen\",\n",
    "    \"huurwoningen\",\n",
    "]\n",
    "data[int_keys] = data[int_keys].astype(int)\n",
    "data[float_keys] = data[float_keys].astype(float)\n",
    "data[perc_keys] = data[perc_keys] / 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.columns.tolist()\n",
    "# data.head()\n",
    "# data.dtypes.to_dict()\n",
    "# data.iloc[0]\n",
    "# {k: (v, d) for k, v, d in zip(data.columns, data.iloc[0], data.dtypes)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = add_indexed_transactions(avix, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = data.dropna(subset=[col for col in data.columns if col != \"house_number_ext\"])\n",
    "# test = test[(test[\"aantal_inwoners\"] != 0) & (test[\"mannen\"] != 0.) * (test[\"vrouwen\"] != 0.)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- ~~column names lowercase~~\n",
    "- ~~check dtypes~~\n",
    "- ~~standaardiseren~~\n",
    "- missing values imputeren\n",
    "- missing buurten imputeren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missingno.bar(data[data.columns[20:40]]);\n",
    "# print(len(test.buurt_code.unique().tolist()))\n",
    "# missingno.matrix(test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = KNNImputer()\n",
    "data = data.replace({pd.np.inf: pd.np.nan})\n",
    "for col in [*float_keys, *int_keys]:\n",
    "    data[col] = imputer.fit_transform(data[col].to_numpy().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "# test[scale_keys] = scaler.fit_transform(test[scale_keys])\n",
    "for col in scale_keys:\n",
    "    data[col] = scaler.fit_transform(data[col].to_numpy().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ProfileReport(data, title=\"Pandas Profiling Report\", html={\"style\":{\"full_width\":True}}, minimal=True)\n",
    "profile.to_file(output_file=path / \"your_report.html\")\n",
    "profile.to_file(output_file=path / \"your_report.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(path / \"complete_hackathon_dataset.csv\", index=False)\n",
    "# test.to_csv(path / \"complete_hackathon_dataset.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
